{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d189734b",
   "metadata": {},
   "source": [
    "## Kaggle Submission File on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf7a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b093f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\julia/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\Documents\\Image2Biomass_BME338\\scripts\n"
     ]
    }
   ],
   "source": [
    "dino = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')#freeze parameters\n",
    "for p in dino.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839ebb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images processed\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def preprocess(img_folder_rel_path,resize):\n",
    "    transformer = v2.Compose([\n",
    "        v2.Resize(size=resize),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    processed_images = []\n",
    "    image_paths = []\n",
    "    folder_path = os.path.join(img_folder_rel_path)\n",
    "    folder_path = folder_path.replace('\\\\', '/')\n",
    "    for file in sorted(os.listdir(folder_path)):\n",
    "        if file.lower().endswith('jpg'):\n",
    "            img_path = os.path.join(folder_path,file)\n",
    "            img_path = img_path.replace('\\\\', '/')\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            trans_img = transformer(img)\n",
    "            processed_images.append(trans_img)\n",
    "            image_paths.append(img_path)\n",
    "    print('Images processed')\n",
    "    print(len(processed_images))\n",
    "    return processed_images, image_paths\n",
    "\n",
    "processed_images, image_paths = preprocess(\"../data/test_2\",224)\n",
    "img_batch = torch.stack(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb427d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384])\n"
     ]
    }
   ],
   "source": [
    "img_batch = torch.stack(processed_images)\n",
    "with torch.no_grad():  \n",
    "    outputs = dino(img_batch)\n",
    "print(outputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4f33d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to ..\\data\\derived\\dino_subm_embeddings.parquet with shape (1, 385)\n"
     ]
    }
   ],
   "source": [
    "features = outputs.detach().cpu().numpy()\n",
    "derived_dir = Path('../data/derived')\n",
    "derived_dir.mkdir(parents=True, exist_ok=True)\n",
    "embeddings_df = pd.DataFrame(features)\n",
    "embeddings_df.insert(0, 'image_path', image_paths)\n",
    "embeddings_path = derived_dir / 'dino_subm_embeddings.parquet'\n",
    "embeddings_df.to_parquet(embeddings_path, index=False)\n",
    "print(f'Saved embeddings to {embeddings_path} with shape {embeddings_df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ee21fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ID4464212\n",
      "Name: img_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "embed = pd.read_parquet(\"../data/derived/dino_subm_embeddings.parquet\")\n",
    "embed[\"img_id\"] = embed[\"image_path\"].str.split(\"/\").str[-1].str.split(\".\").str[0] # select image id's\n",
    "print(embed[\"img_id\"])\n",
    "feature_cols = embed.select_dtypes(include=[np.number]).columns\n",
    "X = embed[feature_cols].to_numpy(dtype=np.float32)\n",
    "X_t = torch.tensor(X, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13709a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=384, hidden_dim=256, output_dim=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cba488a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(input_dim=X_t.shape[1], hidden_dim=256, output_dim=5, dropout=0.2)\n",
    "state = torch.load(\"model_1765703764_918\", map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad26301",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = X_t.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(X_t).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f2a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sample_id      target\n",
      "0  ID4464212_Dry_Clover_g   21.615330\n",
      "1    ID4464212_Dry_Dead_g   33.120743\n",
      "2   ID4464212_Dry_Green_g   57.027294\n",
      "3   ID4464212_Dry_Total_g  116.621193\n",
      "4         ID4464212_GDM_g   82.669510\n"
     ]
    }
   ],
   "source": [
    "target_cols = [\"Dry_Clover_g\", \"Dry_Dead_g\", \"Dry_Green_g\", \"Dry_Total_g\", \"GDM_g\"]\n",
    "\n",
    "pred_df = pd.DataFrame(\n",
    "    preds,\n",
    "    columns=target_cols\n",
    ")\n",
    "pred_df[\"img_id\"] = embed[\"img_id\"].values\n",
    "\n",
    "submission = pred_df.melt(\n",
    "    id_vars=\"img_id\",\n",
    "    value_vars=target_cols,\n",
    "    var_name=\"target_name\",\n",
    "    value_name=\"target\"\n",
    ")\n",
    "\n",
    "submission[\"sample_id\"] = submission[\"img_id\"] + \"_\" + submission[\"target_name\"]\n",
    "submission = submission[[\"sample_id\", \"target\"]]\n",
    "print(submission) \n",
    "submission.to_csv(\"../data/submission/submission.csv\",index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kaggle_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
